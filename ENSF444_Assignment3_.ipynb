{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<font size=\"+3\"><b>Assignment 3: Non-Linear Models and Validation Metrics</b></font>\n",
        "\n",
        "***\n"
      ],
      "metadata": {
        "id": "CNDKREiQRJJX"
      },
      "id": "CNDKREiQRJJX"
    },
    {
      "cell_type": "markdown",
      "id": "ce31b39a",
      "metadata": {
        "id": "ce31b39a"
      },
      "source": [
        "<font color='White'>\n",
        "In this assignment, you will need to write code that uses non-linear models to perform classification and regression tasks. You will also be asked to describe the process by which you came up with the code. More details can be found below. Please cite any websites or AI tools that you used to help you with this assignment.\n",
        "</font>\n",
        "\n",
        "|                **Question**                | **Point** |\n",
        "|:------------------------------------------:|:---------:|\n",
        "|           **Part 1: Regression**           |  **14.5** |\n",
        "|          Step 0: Import Libraries          |           |\n",
        "|             Step 1: Data Input             |    0.5    |\n",
        "|           Step 2: Data Processing          |     0     |\n",
        "| Step 3: Implement   Machine Learning Model |    0.5    |\n",
        "|           Step 4: Validate Model           |    0.5    |\n",
        "|         Step 5: Visualize   Results        |     3     |\n",
        "|                  Questions                 |     6     |\n",
        "|             Process Description            |     4     |\n",
        "|         **Part 2: Classification**         |  **17.5** |\n",
        "|             Step 1: Data Input             |     2     |\n",
        "|           Step 2: Data Processing          |    1.5    |\n",
        "| Step 3: Implement   Machine Learning Model |           |\n",
        "|            Step 4: Validate Mode           |           |\n",
        "|         Step 5: Visualize   Results        |     4     |\n",
        "|                  Questions                 |     6     |\n",
        "|             Process Description            |     4     |\n",
        "|   **Part 3: Observations/Interpretation**  |   **3**   |\n",
        "|           **Part 4: Reflection**           |   **2**   |\n",
        "|                  **Total**                 |   **37**  |\n",
        "|                                            |           |\n",
        "|                  **Bonus**                 |           |\n",
        "|         **Part 5: Bonus Question**         |   **3**   |"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf275ca7",
      "metadata": {
        "id": "cf275ca7"
      },
      "source": [
        "### Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b67a661",
      "metadata": {
        "id": "2b67a661"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ee2d2c3",
      "metadata": {
        "id": "5ee2d2c3"
      },
      "source": [
        "# **Part 1: Regression (14.5 marks)**\n",
        "\n",
        "For this section, we will be continuing with the concrete example from yellowbrick. You will need to compare these results to the results from the previous assignment. Please use the results from the solution if you were unable to complete Assignment 2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8219f163",
      "metadata": {
        "id": "8219f163"
      },
      "source": [
        "## **Step 1:** Data Input (0.5 marks)\n",
        "\n",
        "The data used for this task can be downloaded using the yellowbrick library:\n",
        "https://www.scikit-yb.org/en/latest/api/datasets/concrete.html\n",
        "\n",
        "Use the yellowbrick function `load_concrete()` to load the concrete dataset into the feature matrix `X` and target vector `y`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2af8bd32",
      "metadata": {
        "id": "2af8bd32"
      },
      "outputs": [],
      "source": [
        "# TO DO: Import concrete dataset from yellowbrick library\n",
        "from yellowbrick.datasets import load_concrete\n",
        "\n",
        "X, y = load_concrete()\n",
        "#X is the feature matrix\n",
        "#y is the target matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "42fea4cc",
      "metadata": {
        "id": "42fea4cc"
      },
      "source": [
        "## **Step 2:** Data Processing (0 marks)\n",
        "\n",
        "Data processing was completed in the previous assignment. No need to repeat here.\n",
        "\n",
        "<font color='red'>\n",
        "This is just for your information and no action is required from you for this step.\n",
        "</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2a245d00",
      "metadata": {
        "id": "2a245d00"
      },
      "source": [
        "## **Step 3:** Implement Machine Learning Model (0.5 marks)\n",
        "\n",
        "1. Import the Decision Tree, Random Forest and Gradient Boosting Machines regression models from sklearn\n",
        "2. Instantiate the three models with `max_depth = 5`. Are there any other parameters that you will need to set?\n",
        "3. Implement each machine learning model with `X` and `y`"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "\n",
        "dectrereg = DecisionTreeRegressor(max_depth = 5, random_state = 0)\n",
        "ranforreg = RandomForestRegressor(max_depth = 5, random_state = 0)\n",
        "gradbooreg = GradientBoostingRegressor(max_depth = 5, random_state = 0)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.2, random_state=0)\n",
        "\n",
        "#fit just means you are doing the training on it\n",
        "dectrereg.fit(X_train,y_train)\n",
        "ranforreg.fit(X_train,y_train)\n",
        "gradbooreg.fit(X_train,y_train)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "Hcgdqu99KIfU",
        "outputId": "290925d4-8a72-4ac9-f63a-c04baea42558"
      },
      "id": "Hcgdqu99KIfU",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GradientBoostingRegressor(max_depth=5, random_state=0)"
            ],
            "text/html": [
              "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingRegressor(max_depth=5, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor(max_depth=5, random_state=0)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f994e31",
      "metadata": {
        "id": "3f994e31"
      },
      "source": [
        "## **Step 4:** Validate Model (0.5 marks)\n",
        "\n",
        "Calculate the average training and validation accuracy using mean squared error with cross-validation. To do this, you will need to set `scoring='neg_mean_squared_error'` in your `cross_validate` function and negate the results (multiply by -1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "results_dt = cross_validate(dectrereg, X_train, y_train, scoring='neg_mean_squared_error', cv=5, return_train_score=True)\n",
        "results_rf = cross_validate(ranforreg, X_train, y_train, scoring='neg_mean_squared_error', cv=5, return_train_score=True)\n",
        "results_gb = cross_validate(gradbooreg, X_train, y_train, scoring='neg_mean_squared_error', cv=5, return_train_score=True)\n",
        "\n",
        "avg_train_mse_dt = -1 * np.mean(results_dt['train_score'])\n",
        "avg_train_mse_rf = -1 * np.mean(results_rf['train_score'])\n",
        "avg_train_mse_gb = -1 * np.mean(results_gb['train_score'])\n",
        "\n",
        "avg_val_mse_dt = -1 * np.mean(results_dt['test_score'])\n",
        "avg_val_mse_rf = -1 * np.mean(results_rf['test_score'])\n",
        "avg_val_mse_gb = -1 * np.mean(results_gb['test_score'])\n",
        "\n",
        "\n",
        "dt_pred_train = dectrereg.predict(X_train)\n",
        "dt_r2 = r2_score(y_train, dt_pred_train)\n",
        "\n",
        "rf_pred_train = ranforreg.predict(X_train)\n",
        "rf_r2 = r2_score(y_train, rf_pred_train)\n",
        "\n",
        "gb_pred_train = gradbooreg.predict(X_train)\n",
        "gb_r2 = r2_score(y_train, gb_pred_train)\n",
        "\n",
        "\n",
        "dt_pred_val = dectrereg.predict(X_test)\n",
        "dt_r2_val = r2_score(y_test, dt_pred_val)\n",
        "\n",
        "rf_pred_val = ranforreg.predict(X_test)\n",
        "rf_r2_val = r2_score(y_test, rf_pred_val)\n",
        "\n",
        "gb_pred_val = gradbooreg.predict(X_test)\n",
        "gb_r2_val = r2_score(y_test, gb_pred_val)\n"
      ],
      "metadata": {
        "id": "jQhU4lZwklz4"
      },
      "id": "jQhU4lZwklz4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "5fc3f7a8",
      "metadata": {
        "id": "5fc3f7a8"
      },
      "source": [
        "## **Step 5:** Visualize Results (3 marks)\n",
        "\n",
        "1. Create a pandas DataFrame `results` with columns: Training accuracy and Validation accuracy, and index: DT, RF and GB\n",
        "2. Add the accuracy results to the `results` DataFrame\n",
        "3. Print `results`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fdc93a78",
      "metadata": {
        "id": "fdc93a78",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41348d6e-251c-4121-b7b1-0bf4858396cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    MSE Training accuracy  MSE Validation accuracy  R2 Training accuracy  \\\n",
            "DT              47.822974                74.045335              0.824160   \n",
            "RF              30.296363                47.614708              0.889829   \n",
            "GB               3.694308                23.546500              0.985359   \n",
            "\n",
            "    R2 Validation accuracy  \n",
            "DT                0.734939  \n",
            "RF                0.853822  \n",
            "GB                0.925766  \n"
          ]
        }
      ],
      "source": [
        "\n",
        "data = {\n",
        "    'MSE Training accuracy': [avg_train_mse_dt, avg_train_mse_rf, avg_train_mse_gb],\n",
        "    'MSE Validation accuracy': [avg_val_mse_dt, avg_val_mse_rf, avg_val_mse_gb],\n",
        "    'R2 Training accuracy': [dt_r2, rf_r2, gb_r2],\n",
        "    'R2 Validation accuracy': [dt_r2_val, rf_r2_val, gb_r2_val]\n",
        "}\n",
        "index = ['DT', 'RF', 'GB']\n",
        "results = pd.DataFrame(data, index=index)\n",
        "\n",
        "print(results)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "31715a9d",
      "metadata": {
        "id": "31715a9d"
      },
      "source": [
        "Repeat the step above to print the R2 score instead of the mean-squared error. For this case, you can use `scoring='r2'`.\n",
        "\n",
        "<font color='red'>\n",
        "Due to the similarity of this to the main part of step 5, this part is 0.5 and the main part of step 5 is 2.5 of the total 3 points for this step.\n",
        "</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5257a98",
      "metadata": {
        "id": "a5257a98"
      },
      "source": [
        "## Questions (6 marks)\n",
        "1. ***How do these results compare to the results using a linear model in the previous assignment? Use values.*** In comparing the performance metrics between the linear model from the previous assignment and the decision tree (DT), random forest (RF), and gradient boosting (GB) models from the current assignment, notable differences emerge. The linear model exhibited high training and validation accuracies of approximately 93% and 91%, respectively. However, the models from the current assignment, while showing lower accuracies, demonstrated superior performance in terms of mean squared error (MSE) and R2 score. Specifically, DT exhibited the highest MSE for both training and validation, indicating potential overfitting, whereas RF and GB showcased lower MSE values, with GB achieving the lowest MSE and the highest R2 score for both training and validation. This suggests that RF and GB models generalize better to unseen data compared to the linear model, with GB performing particularly well, showcasing the highest R2 score, indicating a better fit to the data overall. These insights highlight the trade-offs between accuracy and generalization ability, guiding the selection of the most appropriate model for the task at hand.\n",
        "\n",
        "1. ***Out of the models you tested, which model would you select for this dataset and why?*** GB outperformed the other models in terms of MSE, exhibiting the lowest values for both training and validation sets, indicating better overall predictive performance and lower error rates. Additionally, GB achieved the highest R2 score for both training and validation, suggesting a better fit to the data and superior explanatory power. These results imply that the GB model not only minimizes prediction errors but also captures the underlying patterns in the data more effectively compared to the other models tested.\n",
        "\n",
        "1. ***If you wanted to increase the accuracy of the tree-based models, what would you do? Provide two suggestions.*** Firstly, fine-tune hyperparameters such as tree depth and learning rate using methods like grid search or random search to optimize model performance. Secondly, leverage feature engineering to craft new features, transform existing ones, or select the most informative ones, enhancing the model's ability to capture relevant patterns in the data and improve accuracy. These approaches can effectively elevate the performance of tree-based models and address complex data challenges."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "37b238f4",
      "metadata": {
        "id": "37b238f4"
      },
      "source": [
        "## Process Description (4 marks)\n",
        "Please describe the process you used to create your code. Cite any websites or generative AI tools used. You can use the following questions as guidance:\n",
        "1. ***Where did you source your code?***  I sourced my code on this document, other than that the functions that we are meant to use were stated in the steps and from that I used the sckit learn website to see examples on how to use the respective function and what needs to be passed in.  \n",
        "1. ***In what order did you complete the steps?*** I went step by step as I found each step relied on the other.\n",
        "\n",
        "1.  ***If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?*** For the cross validate function, I found that it was only creating an array list with only test_score, so I asked Chatgpt, given this function, how can I get the train score? This helped me retrievre the right values.\n",
        "\n",
        "1.  ***Did you have any challenges? If yes, what were they? If not, what helped you to be successful?***  I didn't encounter significant challenges in completing the task. Understanding the structure of the output from the cross_validate function was a key aspect, but referring to the scikit-learn documentation and using ChatGPT for clarification helped overcome any uncertainties. Overall, the task was straightforward given familiarity with scikit-learn and Python pandas."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f7c6de86",
      "metadata": {
        "id": "f7c6de86"
      },
      "source": [
        "# **Part 2: Classification (17.5 marks)**\n",
        "\n",
        "You have been asked to develop code that can help the user classify different wine samples. Following the machine learning workflow described in class, write the relevant code in each of the steps below:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f9d33a8",
      "metadata": {
        "id": "5f9d33a8"
      },
      "source": [
        "## **Step 1:** Data Input (2 marks)\n",
        "\n",
        "The data used for this task can be downloaded from UCI: https://archive.ics.uci.edu/dataset/109/wine\n",
        "\n",
        "Use the pandas library to load the dataset. You must define the column headers if they are not included in the dataset\n",
        "\n",
        "You will need to split the dataset into feature matrix `X` and target vector `y`. Which column represents the target vector?\n",
        "\n",
        "Print the size and type of `X` and `y`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33583c67",
      "metadata": {
        "id": "33583c67"
      },
      "outputs": [],
      "source": [
        "# TO DO: Import wine dataset\n",
        "import pandas as pd\n",
        "column_headers = ['Class',\n",
        "    'Alcohol', 'Malic Acid', 'Ash', 'Alcalinity of Ash', 'Magnesium',\n",
        "    'Total Phenols', 'Flavanoids', 'Nonflavanoid Phenols', 'Proanthocyanins',\n",
        "    'Color Intensity', 'Hue', 'OD280/OD315 of diluted wines', 'Proline'\n",
        "]\n",
        "\n",
        "wine_data = pd.read_csv('wine.data', header=None, names=column_headers)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "156db208",
      "metadata": {
        "id": "156db208"
      },
      "source": [
        "## **Step 2:** Data Processing (1.5 marks)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a28af110",
      "metadata": {
        "id": "a28af110"
      },
      "source": [
        "Print the first five rows of the dataset to inspect:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea266921",
      "metadata": {
        "id": "ea266921",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "outputId": "6b09a5f4-59e7-4278-e133-cdf74b399e8b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Class  Alcohol  Malic Acid   Ash  Alcalinity of Ash  Magnesium  \\\n",
              "0      1    14.23        1.71  2.43               15.6        127   \n",
              "1      1    13.20        1.78  2.14               11.2        100   \n",
              "2      1    13.16        2.36  2.67               18.6        101   \n",
              "3      1    14.37        1.95  2.50               16.8        113   \n",
              "4      1    13.24        2.59  2.87               21.0        118   \n",
              "\n",
              "   Total Phenols  Flavanoids  Nonflavanoid Phenols  Proanthocyanins  \\\n",
              "0           2.80        3.06                  0.28             2.29   \n",
              "1           2.65        2.76                  0.26             1.28   \n",
              "2           2.80        3.24                  0.30             2.81   \n",
              "3           3.85        3.49                  0.24             2.18   \n",
              "4           2.80        2.69                  0.39             1.82   \n",
              "\n",
              "   Color Intensity   Hue  OD280/OD315 of diluted wines  Proline  \n",
              "0             5.64  1.04                          3.92     1065  \n",
              "1             4.38  1.05                          3.40     1050  \n",
              "2             5.68  1.03                          3.17     1185  \n",
              "3             7.80  0.86                          3.45     1480  \n",
              "4             4.32  1.04                          2.93      735  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-611271c3-7e6f-4474-8d65-7c1ba0b46c1e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Class</th>\n",
              "      <th>Alcohol</th>\n",
              "      <th>Malic Acid</th>\n",
              "      <th>Ash</th>\n",
              "      <th>Alcalinity of Ash</th>\n",
              "      <th>Magnesium</th>\n",
              "      <th>Total Phenols</th>\n",
              "      <th>Flavanoids</th>\n",
              "      <th>Nonflavanoid Phenols</th>\n",
              "      <th>Proanthocyanins</th>\n",
              "      <th>Color Intensity</th>\n",
              "      <th>Hue</th>\n",
              "      <th>OD280/OD315 of diluted wines</th>\n",
              "      <th>Proline</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>14.23</td>\n",
              "      <td>1.71</td>\n",
              "      <td>2.43</td>\n",
              "      <td>15.6</td>\n",
              "      <td>127</td>\n",
              "      <td>2.80</td>\n",
              "      <td>3.06</td>\n",
              "      <td>0.28</td>\n",
              "      <td>2.29</td>\n",
              "      <td>5.64</td>\n",
              "      <td>1.04</td>\n",
              "      <td>3.92</td>\n",
              "      <td>1065</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>13.20</td>\n",
              "      <td>1.78</td>\n",
              "      <td>2.14</td>\n",
              "      <td>11.2</td>\n",
              "      <td>100</td>\n",
              "      <td>2.65</td>\n",
              "      <td>2.76</td>\n",
              "      <td>0.26</td>\n",
              "      <td>1.28</td>\n",
              "      <td>4.38</td>\n",
              "      <td>1.05</td>\n",
              "      <td>3.40</td>\n",
              "      <td>1050</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>13.16</td>\n",
              "      <td>2.36</td>\n",
              "      <td>2.67</td>\n",
              "      <td>18.6</td>\n",
              "      <td>101</td>\n",
              "      <td>2.80</td>\n",
              "      <td>3.24</td>\n",
              "      <td>0.30</td>\n",
              "      <td>2.81</td>\n",
              "      <td>5.68</td>\n",
              "      <td>1.03</td>\n",
              "      <td>3.17</td>\n",
              "      <td>1185</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>14.37</td>\n",
              "      <td>1.95</td>\n",
              "      <td>2.50</td>\n",
              "      <td>16.8</td>\n",
              "      <td>113</td>\n",
              "      <td>3.85</td>\n",
              "      <td>3.49</td>\n",
              "      <td>0.24</td>\n",
              "      <td>2.18</td>\n",
              "      <td>7.80</td>\n",
              "      <td>0.86</td>\n",
              "      <td>3.45</td>\n",
              "      <td>1480</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>13.24</td>\n",
              "      <td>2.59</td>\n",
              "      <td>2.87</td>\n",
              "      <td>21.0</td>\n",
              "      <td>118</td>\n",
              "      <td>2.80</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0.39</td>\n",
              "      <td>1.82</td>\n",
              "      <td>4.32</td>\n",
              "      <td>1.04</td>\n",
              "      <td>2.93</td>\n",
              "      <td>735</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-611271c3-7e6f-4474-8d65-7c1ba0b46c1e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-611271c3-7e6f-4474-8d65-7c1ba0b46c1e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-611271c3-7e6f-4474-8d65-7c1ba0b46c1e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-097f003c-9920-4733-9c6e-aa3836f76970\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-097f003c-9920-4733-9c6e-aa3836f76970')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-097f003c-9920-4733-9c6e-aa3836f76970 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "wine_data",
              "summary": "{\n  \"name\": \"wine_data\",\n  \"rows\": 178,\n  \"fields\": [\n    {\n      \"column\": \"Class\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 3,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1,\n          2,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Alcohol\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.8118265380058575,\n        \"min\": 11.03,\n        \"max\": 14.83,\n        \"num_unique_values\": 126,\n        \"samples\": [\n          11.62,\n          13.64,\n          13.69\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Malic Acid\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.1171460976144627,\n        \"min\": 0.74,\n        \"max\": 5.8,\n        \"num_unique_values\": 133,\n        \"samples\": [\n          1.21,\n          2.83,\n          1.8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Ash\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.27434400906081485,\n        \"min\": 1.36,\n        \"max\": 3.23,\n        \"num_unique_values\": 79,\n        \"samples\": [\n          2.31,\n          2.43,\n          2.52\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Alcalinity of Ash\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.339563767173505,\n        \"min\": 10.6,\n        \"max\": 30.0,\n        \"num_unique_values\": 63,\n        \"samples\": [\n          25.5,\n          28.5,\n          15.6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Magnesium\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 14,\n        \"min\": 70,\n        \"max\": 162,\n        \"num_unique_values\": 53,\n        \"samples\": [\n          126,\n          85,\n          162\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Total Phenols\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.6258510488339893,\n        \"min\": 0.98,\n        \"max\": 3.88,\n        \"num_unique_values\": 97,\n        \"samples\": [\n          1.68,\n          2.11,\n          1.35\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Flavanoids\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9988586850169467,\n        \"min\": 0.34,\n        \"max\": 5.08,\n        \"num_unique_values\": 132,\n        \"samples\": [\n          3.18,\n          2.5,\n          3.17\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Nonflavanoid Phenols\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.12445334029667937,\n        \"min\": 0.13,\n        \"max\": 0.66,\n        \"num_unique_values\": 39,\n        \"samples\": [\n          0.58,\n          0.41,\n          0.39\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Proanthocyanins\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5723588626747613,\n        \"min\": 0.41,\n        \"max\": 3.58,\n        \"num_unique_values\": 101,\n        \"samples\": [\n          0.75,\n          1.77,\n          1.42\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Color Intensity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.318285871822413,\n        \"min\": 1.28,\n        \"max\": 13.0,\n        \"num_unique_values\": 132,\n        \"samples\": [\n          2.95,\n          3.3,\n          5.1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Hue\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.22857156582982338,\n        \"min\": 0.48,\n        \"max\": 1.71,\n        \"num_unique_values\": 78,\n        \"samples\": [\n          1.22,\n          1.04,\n          1.45\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"OD280/OD315 of diluted wines\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7099904287650504,\n        \"min\": 1.27,\n        \"max\": 4.0,\n        \"num_unique_values\": 122,\n        \"samples\": [\n          4.0,\n          1.82,\n          1.59\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Proline\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 314,\n        \"min\": 278,\n        \"max\": 1680,\n        \"num_unique_values\": 121,\n        \"samples\": [\n          1375,\n          1270,\n          735\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "# TO DO: ADD YOUR CODE HERE\n",
        "wine_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "834fc8fe",
      "metadata": {
        "id": "834fc8fe"
      },
      "source": [
        "Check to see if there are any missing values in the dataset. If necessary, select an appropriate method to fill-in the missing values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97c6e9dc",
      "metadata": {
        "id": "97c6e9dc"
      },
      "outputs": [],
      "source": [
        "# TO DO: ADD YOUR CODE HERE\n",
        "missing_values = wine_data.isnull().sum().all()\n",
        "if missing_values:\n",
        "    for column in column_headers:\n",
        "        if wine_data[column].isnull().any():\n",
        "            wine_data[column].fillna(wine_data[column].mean(), inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "070956af",
      "metadata": {
        "id": "070956af"
      },
      "source": [
        "How many samples do we have of each type of wine?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b37a6fd9",
      "metadata": {
        "id": "b37a6fd9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e8e8a6c-6abf-4e25-dd03-b4ebdaa485f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples of each type of wine:\n",
            "2    71\n",
            "1    59\n",
            "3    48\n",
            "Name: Class, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# TO DO: ADD YOUR CODE HERE\n",
        "wine_counts = wine_data['Class'].value_counts()\n",
        "\n",
        "print(\"Number of samples of each type of wine:\")\n",
        "print(wine_counts)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "70e6c46f",
      "metadata": {
        "id": "70e6c46f"
      },
      "source": [
        "## **Step 3:** Implement Machine Learning Model\n",
        "\n",
        "1. Import `SVC` and `DecisionTreeClassifier` from sklearn\n",
        "2. Instantiate models as `SVC()` and `DecisionTreeClassifier(max_depth = 3)`\n",
        "3. Implement the machine learning model with `X` and `y`"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "X = wine_data.drop('Class')\n",
        "y = wine_data['Class']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=42)\n",
        "\n",
        "svc_model = SVC()\n",
        "dt_model = DecisionTreeClassifier(max_depth=3)\n",
        "svc_model.fit(X_train, y_train)\n",
        "dt_model.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "9A7F75X6hfFC",
        "outputId": "bd7b4531-a869-420a-da18-231be28ab413"
      },
      "id": "9A7F75X6hfFC",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(max_depth=3)"
            ],
            "text/html": [
              "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(max_depth=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=3)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0870b0d2",
      "metadata": {
        "id": "0870b0d2"
      },
      "source": [
        "## **Step 4:** Validate Model\n",
        "\n",
        "Calculate the average training and validation accuracy using `cross_validate` for the two different models listed in Step 3. For this case, use `scoring='accuracy'`"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform cross-validation and calculate average training and validation accuracy\n",
        "svc_cv_results = cross_validate(svc_model, X_train, y_train, scoring='accuracy', cv=5, return_train_score=True)\n",
        "dt_cv_results = cross_validate(dt_model, X_train, y_train, scoring='accuracy', cv=5, return_train_score=True)\n",
        "\n",
        "# Calculate average training and validation accuracy for SVC\n",
        "avg_train_accuracy_svc = svc_cv_results['train_score'].mean()\n",
        "avg_val_accuracy_svc = svc_cv_results['test_score'].mean()\n",
        "\n",
        "# Calculate average training and validation accuracy for DecisionTreeClassifier\n",
        "avg_train_accuracy_dt = dt_cv_results['train_score'].mean()\n",
        "avg_val_accuracy_dt = dt_cv_results['test_score'].mean()\n",
        "\n",
        "print(avg_train_accuracy_dt)\n",
        "print(avg_val_accuracy_dt)\n",
        "print(avg_val_accuracy_svc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Snf33trsY1o",
        "outputId": "00d27546-31d0-4db5-9107-9f814d64438c"
      },
      "id": "8Snf33trsY1o",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9929669306008384\n",
            "0.9224137931034484\n",
            "0.6485221674876847\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb0bbd83",
      "metadata": {
        "id": "bb0bbd83"
      },
      "source": [
        "## **Step 5:** Visualize Results (4 marks)\n",
        "\n",
        "<font color='red'>\n",
        "There is no individual mark for Steps 3 and 4 and those grades are included within the four points.\n",
        "\n",
        "</font>\n",
        "\n",
        "### **Step 5.1:** Compare Models (2 out of total 4 marks)\n",
        "1. Create a pandas DataFrame `results` with columns: Training accuracy and Validation accuracy\n",
        "2. Add the data size, training and validation accuracy for each dataset to the `results` DataFrame\n",
        "3. Print `results`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be4b5c0a",
      "metadata": {
        "id": "be4b5c0a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5377e316-92eb-47a0-cafd-904d9dc4ee14"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                         Training accuracy  Validation accuracy\n",
            "Data Size                       142.000000           142.000000\n",
            "SVC                               0.672597             0.648522\n",
            "Decision Tree Classifer           0.992967             0.922414\n"
          ]
        }
      ],
      "source": [
        "# TO DO: ADD YOUR CODE HERE FOR STEPS 3-5\n",
        "# Note: for any random state parameters, you can use random_state = 0\n",
        "# HINT: USING A LOOP TO STORE THE DATA IN YOUR RESULTS DATAFRAME WILL BE MORE EFFICIENT\n",
        "\n",
        "data = {\n",
        "    'Training accuracy': [X_train.shape[0], avg_train_accuracy_svc, avg_train_accuracy_dt],\n",
        "    'Validation accuracy': [X_train.shape[0], avg_val_accuracy_svc, avg_val_accuracy_dt]\n",
        "}\n",
        "index = ['Data Size', 'SVC', 'Decision Tree Classifer']\n",
        "results = pd.DataFrame(data, index=index)\n",
        "\n",
        "print(results)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2e17878",
      "metadata": {
        "id": "f2e17878"
      },
      "source": [
        "### **Step 5.2:** Visualize Classification Errors  (2 out of total 4 marks)\n",
        "Which method gave the highest accuracy? Use this method to print the confusion matrix and classification report:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "44b091a4",
      "metadata": {
        "id": "44b091a4"
      },
      "outputs": [],
      "source": [
        "# TO DO: Implement best model\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "y_pred = dt_model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09d21b59",
      "metadata": {
        "id": "09d21b59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 616
        },
        "outputId": "cba0ce05-3671-4eb3-de63-2d46996bf30d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[13  1  0]\n",
            " [ 0 14  0]\n",
            " [ 0  1  7]]\n"
          ]
        }
      ],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "plt.xlabel(\"Predicted labels\")\n",
        "plt.ylabel(\"True labels\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()\n",
        "\n",
        "print(conf_matrix)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ef95947",
      "metadata": {
        "id": "5ef95947",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2883a8e9-a5df-4e01-f5b8-d250805dcbeb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.93      0.96        14\n",
            "           2       0.88      1.00      0.93        14\n",
            "           3       1.00      0.88      0.93         8\n",
            "\n",
            "    accuracy                           0.94        36\n",
            "   macro avg       0.96      0.93      0.94        36\n",
            "weighted avg       0.95      0.94      0.94        36\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# TO DO: Print classification report\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf319621",
      "metadata": {
        "id": "bf319621"
      },
      "source": [
        "## Questions (6 marks)\n",
        "1. ***How do the training and validation accuracy change depending on the method used? Explain with values.*** The classification report provides a comprehensive overview of the model's performance on both the training and validation sets. Precision, recall, and F1-score metrics indicate the model's accuracy, ability to correctly classify positive samples, and balance between precision and recall, respectively. With precision ranging from 0.88 to 1.00 and recall from 0.88 to 1.00, the model exhibits consistent performance across different classes. The F1-score, ranging from 0.93 to 0.96, demonstrates a good balance between precision and recall. Overall accuracy stands at 0.94, reflecting the model's ability to correctly classify 94% of the samples in the validation set. The values of these metrics remain stable across different classification methods, offering a reliable assessment of the model's effectiveness in classifying wine samples.\n",
        "1. ***What are two reasons why the support vector machines model did not work as well as the tree-based model?*** ONE: Over generalization/ It is hard to grasp complex relationships. This is one of the flaws of the SVMs, the hyperplane might be off because it might struggle to achieve the relationships between complex targets and features. While as decision tress are constantly recursively partitioning a feature space providing room to analyze the complex relationships in a more simplifed environment. TWO:  SVMs have hyperparameters such as the choice of kernel function, regularization parameter, and kernel parameters. If these hyperparameters are not chosen appropriately, SVMs may underperform. In contrast, Decision Tree classifiers are less sensitive to hyperparameters.\n",
        "1. ***How many samples were incorrectly classified in step 5.2?*** 2 were incorrectly classifed\n",
        "1. ***In this case, is maximizing precision or recall more important? Why?***  Maximizing precision would result in more commerical factors, whether the company loses money or based on a lack of worthy ads. However, mazimizing recall would result in some harms in the sense of health. In cases where wines with specific health benefits (e.g., antioxidants, low sulfites) need to be identified, false negatives could deprive consumers of valuable information. Maximizing recall ensures that wines with desirable health properties are correctly classified and highlighted for consumers.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "664ff8ae",
      "metadata": {
        "id": "664ff8ae"
      },
      "source": [
        "## Process Description (4 marks)\n",
        "Please describe the process you used to create your code. Cite any websites or generative AI tools used. You can use the following questions as guidance:\n",
        "1. ***Where did you source your code?*** For this I used the powerpoint slides in class and once again the scikit learn tools website to understand what parameters needed to be passed through.\n",
        "1. ***In what order did you complete the steps?*** I just went step by step.\n",
        "1. ***If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?*** For this I did not use any generative AI because it was very similar to other assignments and labs.\n",
        "1. ***Did you have any challenges? If yes, what were they? If not, what helped you to be successful?*** I didnt experience any challenges in this one, as this part was similar to a lot of other labs and assignments, and the generation of SVC and the tree was a simple look at the sklearn documentation."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4cd7358d",
      "metadata": {
        "id": "4cd7358d"
      },
      "source": [
        "# **Part 3: Observations/Interpretation (3 marks)**\n",
        "\n",
        "***Describe any pattern you see in the results. Relate your findings to what we discussed during lectures. Include data to justify your findings.***\n",
        "\n",
        "From the classification report and the provided data, several patterns emerge. First, looking at the precision, recall, and F1-score for each class, we notice a consistent trend across classes 1, 2, and 3. Class 1 and Class 3 both exhibit perfect precision (1.00), while Class 2 has slightly lower precision (0.88). This indicates that the model tends to make fewer false positive predictions for Class 1 and Class 3 compared to Class 2. However, Class 2 has perfect recall (1.00), meaning the model correctly identifies all instances of Class 2 in the validation set, whereas Class 1 and Class 3 have lower recall (0.93 and 0.88, respectively). This suggests that the model may miss some instances of Class 1 and Class 3 during classification. Additionally, the F1-score, which balances precision and recall, shows consistent performance across all classes, with values ranging from 0.93 to 0.96, indicating a good balance between precision and recall for each class. Furthermore, comparing the training and validation accuracy for both the Support Vector Machine (SVC) and Decision Tree Classifier, we observe a slight drop in validation accuracy compared to training accuracy for both models, which is expected due to generalization to unseen data. However, the Decision Tree Classifier shows a more significant drop in accuracy compared to SVC, which might suggest overfitting to the training data with the Decision Tree Classifier. These findings align with concepts discussed in lectures, such as the trade-off between precision and recall, the impact of overfitting on model performance, and the importance of evaluating models on validation data to assess generalization."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd97b6ac",
      "metadata": {
        "id": "cd97b6ac"
      },
      "source": [
        "## **Part 4:** Reflection (2 marks)\n",
        "\n",
        "\n",
        "I like the diverse types of datasets we go over, this shows an implication of how datascience and machine learning is used in almost every aspect of life - last assignment was spam mail and now we are doing wines. I appreciate that there are libraries like sklearn that we can use to make our lives easier, but it would be cool if we could go the functions themselves.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fa21e53b",
      "metadata": {
        "id": "fa21e53b"
      },
      "source": [
        "## **Part 5:** Bonus Question (3 marks)\n",
        "\n",
        "Repeat Part 2 and compare the support vector machines model used to `LinearSVC(max_iter=5000)`. Does using `LinearSVC` improve the results? Why or why not?\n",
        "\n",
        "Is `LinearSVC` a good fit for this dataset? Why or why not?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aabc68a4",
      "metadata": {
        "id": "aabc68a4"
      },
      "source": [
        "Linear SVC emerges as a much superior model compared to the standard SVC (with training accuracy of 0.721671 and validation accuracy of 0.718478), while linear models exhibit significantly higher accuracy (with training accuracy of 0.9001358695652174 and validation accuracy of 0.8934782608695653). This implies a more precise fit to unseen data and superior generalization capability. Linear SVC also offers more interpretable outcomes in contrast to standard SVC with non-linear kernels. The decision boundary in Linear SVC is represented by a hyperplane, facilitating easy visualization and comprehension, which contributes to a clearer understanding of the model's predictions and the underlying classification process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "241c3b12",
      "metadata": {
        "id": "241c3b12",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d439c46-c88c-40a8-eb7c-767fdbe6da40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "scv_linear_model = LinearSVC(max_iter = 5000)\n",
        "scv_linear_model.fit(X_train, y_train)\n",
        "\n",
        "svc_linear_cv_results = cross_validate(scv_linear_model, X_train, y_train, scoring = 'accuracy', cv =5, return_train_score=True)\n",
        "svc_train_cv_avf = svc_linear_cv_results['train_score'].mean()\n",
        "svc_val_cv_avf = svc_linear_cv_results['test_score'].mean()\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
